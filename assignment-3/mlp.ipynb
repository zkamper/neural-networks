{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T22:14:21.534620Z",
     "start_time": "2024-11-05T22:12:45.374476Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "data = np.load('mnist_data.npz')\n",
    "train_X = data['train_X']\n",
    "train_Y = data['train_Y']\n",
    "\n",
    "def split_data(data, batch_size):\n",
    "    return [data[i:i + batch_size] for i in range(0, len(data), batch_size)]\n",
    "\n",
    "def softmax(y: np.ndarray) -> np.ndarray:\n",
    "    exp_y = np.exp(y - np.max(y, axis=1, keepdims=True))\n",
    "    return exp_y / np.sum(exp_y, axis=1, keepdims=True)\n",
    "\n",
    "def classify(y: np.ndarray, label: np.ndarray):\n",
    "    return np.sum(np.argmax(y, axis=1) == np.argmax(label, axis=1))\n",
    "\n",
    "def cross_entropy(y: np.ndarray, label: np.ndarray):\n",
    "    return np.mean(-np.sum(label * np.log(y), axis=1))\n",
    "\n",
    "def sigmoid(x: np.ndarray):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x: np.ndarray):\n",
    "    sig = sigmoid(x)\n",
    "    return sig * (1 - sig)\n",
    "\n",
    "def forward_prop(x: np.array, w_1: np.array, b_1: np.array, w_2: np.array, b_2: np.array):\n",
    "    global DROPOUT_RATE\n",
    "    z_1 = x.dot(w_1) + b_1\n",
    "    a_1 = sigmoid(z_1)\n",
    "    # dropout pe hidden layer\n",
    "    a_1 = np.where(np.random.rand(*a_1.shape) < DROPOUT_RATE, 0, a_1)\n",
    "    a_1 /= (1-DROPOUT_RATE)\n",
    "    z_2 = a_1.dot(w_2) + b_2\n",
    "    y = softmax(z_2)\n",
    "    return y, z_1, a_1\n",
    "\n",
    "def back_prop(x: np.array, y: np.array, label: np.array, w_1: np.array, b_1: np.array, w_2: np.array, b_2: np.array, z_1: np.array, a_1: np.array):\n",
    "    global ALPHA, BATCH_SIZE\n",
    "    error_out = y - label\n",
    "    error_hidden = error_out.dot(w_2.T) * sigmoid_derivative(z_1)\n",
    "\n",
    "    grad_w_2 = a_1.T.dot(error_out)\n",
    "    grad_b_2 = np.mean(error_out, axis=0) / BATCH_SIZE\n",
    "    grad_w_1 = x.T.dot(error_hidden)\n",
    "    grad_b_1 = np.mean(error_hidden, axis=0) / BATCH_SIZE\n",
    "\n",
    "    w_2 -= ALPHA * grad_w_2\n",
    "    b_2 -= ALPHA * grad_b_2\n",
    "    w_1 -= ALPHA * grad_w_1\n",
    "    b_1 -= ALPHA * grad_b_1\n",
    "\n",
    "\n",
    "def train_mini_batch(x: np.array, label: np.array):\n",
    "    global w_1, b_1, w_2, b_2\n",
    "    y, z_1, a_1 = forward_prop(x, w_1, b_1, w_2, b_2)\n",
    "    back_prop(x, y, label, w_1, b_1, w_2, b_2, z_1, a_1)\n",
    "    return cross_entropy(y, label)\n",
    "\n",
    "def train(dataset):\n",
    "    global BATCH_SIZE\n",
    "\n",
    "    batches = split_data(dataset, BATCH_SIZE)\n",
    "\n",
    "    cost = 0\n",
    "    for batch in batches:\n",
    "        x = np.array([data[0] for data in batch])\n",
    "        label = np.array([data[1] for data in batch])\n",
    "        cost += train_mini_batch(x, label)\n",
    "    return cost / len(batches)\n",
    "\n",
    "w_1 = np.random.randn(784, 100) * 0.01\n",
    "b_1 = np.zeros(100)\n",
    "w_2 = np.random.randn(100, 10) * 0.01\n",
    "b_2 = np.zeros(10)\n",
    "\n",
    "ALPHA = 0.02\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 100\n",
    "DROPOUT_RATE = 0.1\n",
    "\n",
    "train_data = list(zip(train_X, train_Y))\n",
    "train_data_len = len(train_data)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    if i == 20:\n",
    "        ALPHA = 0.01\n",
    "    np.random.shuffle(train_data)\n",
    "    avg_cost = train(train_data)\n",
    "    print(f'Epoch {i + 1}/{EPOCHS}, cost: {avg_cost}')\n",
    "\n",
    "end_time = time.time()\n",
    "print(f'Training took {end_time - start_time} seconds')\n",
    "# Save the model\n",
    "np.savez('model.npz', w_1 = w_1, b_1 = b_1, w_2 = w_2, b_2 = b_2)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, cost: 0.5142958708022438\n",
      "Epoch 2/100, cost: 0.20876747475652513\n",
      "Epoch 3/100, cost: 0.15866709322471412\n",
      "Epoch 4/100, cost: 0.13274000007857004\n",
      "Epoch 5/100, cost: 0.11684181421890318\n",
      "Epoch 6/100, cost: 0.10271632526706834\n",
      "Epoch 7/100, cost: 0.09397134607232481\n",
      "Epoch 8/100, cost: 0.084781710185388\n",
      "Epoch 9/100, cost: 0.07716728845626789\n",
      "Epoch 10/100, cost: 0.0721471079378226\n",
      "Epoch 11/100, cost: 0.06718456796091674\n",
      "Epoch 12/100, cost: 0.06381017531121587\n",
      "Epoch 13/100, cost: 0.060520348392512795\n",
      "Epoch 14/100, cost: 0.05826548814325722\n",
      "Epoch 15/100, cost: 0.05450799379591004\n",
      "Epoch 16/100, cost: 0.0506437479880307\n",
      "Epoch 17/100, cost: 0.048361315173451214\n",
      "Epoch 18/100, cost: 0.046326395876798834\n",
      "Epoch 19/100, cost: 0.04269950578955096\n",
      "Epoch 20/100, cost: 0.042286686538144276\n",
      "Epoch 21/100, cost: 0.03609565023534182\n",
      "Epoch 22/100, cost: 0.03495551400304291\n",
      "Epoch 23/100, cost: 0.03592162323300867\n",
      "Epoch 24/100, cost: 0.03319238710991882\n",
      "Epoch 25/100, cost: 0.033274846419743834\n",
      "Epoch 26/100, cost: 0.03214864187602435\n",
      "Epoch 27/100, cost: 0.03174933491139543\n",
      "Epoch 28/100, cost: 0.031377755231209475\n",
      "Epoch 29/100, cost: 0.03147783892178479\n",
      "Epoch 30/100, cost: 0.03003638904282423\n",
      "Epoch 31/100, cost: 0.029935490960062074\n",
      "Epoch 32/100, cost: 0.027463417705076203\n",
      "Epoch 33/100, cost: 0.02748368614846937\n",
      "Epoch 34/100, cost: 0.02710813664844868\n",
      "Epoch 35/100, cost: 0.02775473144184603\n",
      "Epoch 36/100, cost: 0.02750965408012768\n",
      "Epoch 37/100, cost: 0.025944266431153558\n",
      "Epoch 38/100, cost: 0.025800558155105482\n",
      "Epoch 39/100, cost: 0.025905273689455745\n",
      "Epoch 40/100, cost: 0.026526957442954916\n",
      "Epoch 41/100, cost: 0.025962868639497337\n",
      "Epoch 42/100, cost: 0.025417897764264688\n",
      "Epoch 43/100, cost: 0.024038822717009096\n",
      "Epoch 44/100, cost: 0.02566537187493424\n",
      "Epoch 45/100, cost: 0.02422525902265431\n",
      "Epoch 46/100, cost: 0.024072650533130374\n",
      "Epoch 47/100, cost: 0.023173874886459125\n",
      "Epoch 48/100, cost: 0.023420505404572623\n",
      "Epoch 49/100, cost: 0.023003725607593967\n",
      "Epoch 50/100, cost: 0.02266682514984647\n",
      "Epoch 51/100, cost: 0.02125971488806887\n",
      "Epoch 52/100, cost: 0.022461474189221765\n",
      "Epoch 53/100, cost: 0.02158067327711332\n",
      "Epoch 54/100, cost: 0.021365084974718423\n",
      "Epoch 55/100, cost: 0.021860421774847993\n",
      "Epoch 56/100, cost: 0.019871964036688693\n",
      "Epoch 57/100, cost: 0.02073048140673819\n",
      "Epoch 58/100, cost: 0.019146334634806476\n",
      "Epoch 59/100, cost: 0.02029580019975238\n",
      "Epoch 60/100, cost: 0.021014826249323357\n",
      "Epoch 61/100, cost: 0.01961659170989078\n",
      "Epoch 62/100, cost: 0.0195846973881586\n",
      "Epoch 63/100, cost: 0.01926804165671852\n",
      "Epoch 64/100, cost: 0.019195964240828596\n",
      "Epoch 65/100, cost: 0.01906170488547689\n",
      "Epoch 66/100, cost: 0.019287795204432592\n",
      "Epoch 67/100, cost: 0.019937680596795522\n",
      "Epoch 68/100, cost: 0.018061511601146392\n",
      "Epoch 69/100, cost: 0.01973674881895239\n",
      "Epoch 70/100, cost: 0.018329350064001597\n",
      "Epoch 71/100, cost: 0.017267330740733486\n",
      "Epoch 72/100, cost: 0.017622704008573072\n",
      "Epoch 73/100, cost: 0.016115732594016496\n",
      "Epoch 74/100, cost: 0.01692878168160573\n",
      "Epoch 75/100, cost: 0.016268544208470855\n",
      "Epoch 76/100, cost: 0.017162906225129455\n",
      "Epoch 77/100, cost: 0.019159989501125144\n",
      "Epoch 78/100, cost: 0.017141519244412786\n",
      "Epoch 79/100, cost: 0.01650629894387413\n",
      "Epoch 80/100, cost: 0.01684737545283414\n",
      "Epoch 81/100, cost: 0.01611488181264363\n",
      "Epoch 82/100, cost: 0.015250162249027746\n",
      "Epoch 83/100, cost: 0.015904438402406813\n",
      "Epoch 84/100, cost: 0.016349277795719923\n",
      "Epoch 85/100, cost: 0.01564391962150738\n",
      "Epoch 86/100, cost: 0.015758292252640534\n",
      "Epoch 87/100, cost: 0.016070342761672123\n",
      "Epoch 88/100, cost: 0.015576322315269472\n",
      "Epoch 89/100, cost: 0.015430292278981772\n",
      "Epoch 90/100, cost: 0.015434119253037325\n",
      "Epoch 91/100, cost: 0.01428627526756513\n",
      "Epoch 92/100, cost: 0.014838858082072548\n",
      "Epoch 93/100, cost: 0.014150583105935246\n",
      "Epoch 94/100, cost: 0.013988005768796496\n",
      "Epoch 95/100, cost: 0.014075970294023398\n",
      "Epoch 96/100, cost: 0.014042311252822346\n",
      "Epoch 97/100, cost: 0.014971136061306638\n",
      "Epoch 98/100, cost: 0.014164905098692756\n",
      "Epoch 99/100, cost: 0.013427293434450578\n",
      "Epoch 100/100, cost: 0.013896572200218525\n",
      "Training took 95.59964179992676 seconds\n"
     ]
    }
   ],
   "execution_count": 14
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
