{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-16T21:25:48.538332Z",
     "start_time": "2024-10-16T21:25:45.622185Z"
    }
   },
   "source": [
    "import queue\n",
    "\n",
    "import numpy as np\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "def download_mnist(is_train: bool):\n",
    "    dataset = MNIST(root='./data',\n",
    "                    transform=lambda x: np.array(x).flatten(),\n",
    "                    download=True,\n",
    "                    train=is_train)\n",
    "    mnist_data = []\n",
    "    mnist_labels = []\n",
    "    for image, label in dataset:\n",
    "        mnist_data.append(image)\n",
    "        mnist_labels.append(label)\n",
    "        \n",
    "    return mnist_data, mnist_labels"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T20:24:52.246423Z",
     "start_time": "2024-10-16T20:24:49.178262Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_X, train_Y = download_mnist(is_train=True)\n",
    "test_X, test_Y = download_mnist(is_train=False)"
   ],
   "id": "8bed2677066e8ed1",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Normalizarea inputului\n",
   "id": "83603436548ad2fd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T20:24:57.927512Z",
     "start_time": "2024-10-16T20:24:57.489699Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def normalize_input(lst: list[int]):\n",
    "    return [x / 255 for x in lst]\n",
    "\n",
    "train_X = normalize_input(train_X)\n",
    "test_X = normalize_input(test_X)"
   ],
   "id": "6ec9e47e45bf12e4",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T20:24:59.690222Z",
     "start_time": "2024-10-16T20:24:59.539382Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def label_encoding(labels: list[int]) -> list[list[int]]:\n",
    "    return [[1 if label == i else 0 for i in range(10)] for label in labels]\n",
    "\n",
    "train_Y = label_encoding(train_Y)\n",
    "test_Y = label_encoding(test_Y)"
   ],
   "id": "622a63fd8d3fab90",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Salvare/Incarcare date\n",
    "Pentru a nu descărca de atâtea ori, salvam si incarcam de pe disc datele deja prelucrate"
   ],
   "id": "53f549ec1f3fc743"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T20:25:03.522086Z",
     "start_time": "2024-10-16T20:25:02.627055Z"
    }
   },
   "cell_type": "code",
   "source": [
    "np.savez('mnist_data.npz',\n",
    "         train_X=train_X,\n",
    "         train_Y=train_Y,\n",
    "         test_X=test_X,\n",
    "         test_Y=test_Y)"
   ],
   "id": "c615cc04345e7475",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T21:25:43.853994Z",
     "start_time": "2024-10-16T21:25:43.506326Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.load('mnist_data.npz')\n",
    "train_X = data['train_X']\n",
    "train_Y = data['train_Y']\n",
    "test_X = data['test_X']\n",
    "test_Y = data['test_Y']"
   ],
   "id": "123e93d68598794c",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Funcția de antrenare a unui batch",
   "id": "5ad1e63bea275ac8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T21:25:52.852920Z",
     "start_time": "2024-10-16T21:25:52.848546Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def classify(y: np.ndarray[10], label: np.ndarray[10]):\n",
    "    return np.argmax(y) == np.argmax(label)\n",
    "\n",
    "def softmax(y: np.ndarray[10]):\n",
    "    return np.exp(y) / np.sum(np.exp(y))\n",
    "\n",
    "def cross_entropy(y: np.ndarray[10], label: np.ndarray[10]):\n",
    "    return - np.sum(label * np.log(y))"
   ],
   "id": "e8f8a06a4bcdaf82",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T21:25:54.893598Z",
     "start_time": "2024-10-16T21:25:54.889510Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_thread(train_set, weights: np.ndarray, biases: np.ndarray, learning_rate: float, result_queue: queue.Queue):\n",
    "    thread_weights = np.zeros(weights.shape)\n",
    "    thread_biases = np.zeros(biases.shape)\n",
    "    batches = [train_set[i:i + 100] for i in range(0, len(train_set), 100)]\n",
    "    for batch in batches:\n",
    "        temp_weights, temp_biases = train(batch, weights, biases, learning_rate)\n",
    "        thread_weights = thread_weights + temp_weights\n",
    "        thread_biases = thread_biases + temp_biases\n",
    "    result_queue.put((thread_weights, thread_biases))"
   ],
   "id": "ed68e63e5cafb516",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T21:25:56.580764Z",
     "start_time": "2024-10-16T21:25:56.575913Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train(train_set, weights: np.ndarray, biases: np.ndarray, learning_rate):\n",
    "    temp_weights = np.zeros(weights.shape)\n",
    "    temp_biases = np.zeros(biases.shape)\n",
    "    for x, label in train_set:\n",
    "        z = x.dot(weights) + biases\n",
    "        y = softmax(z)\n",
    "        if not classify(y, label):\n",
    "            temp_weights = temp_weights + learning_rate * (label - y) * np.transpose(x)\n",
    "            temp_biases = temp_biases + learning_rate * (label - y)\n",
    "    return temp_weights, temp_biases"
   ],
   "id": "549f52b370557576",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import threading\n",
    "\n",
    "weights = np.zeros((784, 10))\n",
    "biases = np.zeros(10)\n",
    "alpha = 0.01\n",
    "epochs = 3\n",
    "num_threads = 8\n",
    "\n",
    "train_data = list(zip(train_X, train_Y))\n",
    "train_data_len = len(train_data)\n",
    "thread_set_size = train_data_len // num_threads\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    threads = []\n",
    "    result_queue = queue.Queue()\n",
    "    thread_batches = [train_data[i:i + thread_set_size] for i in range(0, train_data_len, thread_set_size)]\n",
    "    for i in range(num_threads):\n",
    "        thread = threading.Thread(target=train_thread, args=(train_data, weights, biases, alpha, result_queue))\n",
    "        threads.append(thread)\n",
    "        thread.start()\n",
    "        \n",
    "    for t in threads:\n",
    "        t.join()\n",
    "        \n",
    "    for i in range(num_threads):\n",
    "        temp_weights, temp_biases = result_queue.get()\n",
    "        weights = weights + temp_weights\n",
    "        biases = biases + temp_biases\n",
    "    \n",
    "    print(f'Epoch {epoch + 1} done')\n",
    "    \n",
    "# Save the model\n",
    "np.savez('model.npz', weights=weights, biases=biases)"
   ],
   "id": "1f588ddd69e68429",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "ab14222ffffea7e7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
